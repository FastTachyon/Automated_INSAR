{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# NASA International Space Apps Challenge - InSAR Change Detectives!\n",
    "\n",
    "Team LTI Software and Engineering:\n",
    "\n",
    " - Alexandre Beaulieu\n",
    " - Mathieu Bergeron\n",
    " - Gabriel Gibeau Sanchez\n",
    " - Olivier Lavergne\n",
    " - Maxime Rondeau\n",
    "\n",
    "## Overview\n",
    "Here are the processing steps.\n",
    "\n",
    "### Data source\n",
    "#### Satellite products\n",
    "We use L1 data from the SENTINEL-1A Interferometric Wide Swath Level 1 S Product. Data are downloaded via the [python scripts](data/download_2015NepalEarthquake.py) provided by the Alaska Satellite Facility's [bulk download service][asf].\n",
    "\n",
    "#### Weather data\n",
    "We use weather data from the [Copernicus Climate Change Service (C3S) Climate Data Store][atmopspheric-data]. There is a utility scrip to download the atmospheric data corresponding to three geological events of interest; namely the Ridgecrest, CA, USA earthquakes of July 4th and 5th 2019, the Kilauea, HI, USA volcanic eruption of May 4th 2018 and the Kumamoto, KYU, Japan earthquake of April 16th 2016. The files have also been pushed to the repository for your convinience.\n",
    "\n",
    "##### ERA5 data download script\n",
    "\n",
    "Once the steps (found [here](https://confluence.ecmwf.int/display/CKB/How+to+install+and+use+CDS+API+on+Windows) *Note: The .cdspapirc file need to be created manually for Windows user) to create a login for ERA5's API have been completed, atmospheric data can be easily downloaded the query(ies) string(s) in the `ERA5APICalls.py` script. Example of queries can be obtained from https://cds.climate.copernicus.eu/cdsapp#!/dataset/reanalysis-era5-pressure-levels?tab=form.\n",
    "\n",
    "### Processing steps\n",
    "To generate an interferogram, Level 1 data is preprocessed using the following steps, similar the example found at [this repository][sentinel-1-snappy].\n",
    " 1.  Open source files\n",
    " 2.  Select chosen subswath\n",
    " 3.  Apply Geocoding\n",
    " 4.  Burst co-registration using orbit and (digital elevation map) DEM\n",
    " 5.  Estimate constant range and azimuth offsets for the whole image\n",
    " 6.  Compute interferogram\n",
    " 7.  Debursts the TOPSAR product\n",
    " 8.  Compute and subtract topographic phase\n",
    " 9.  Multilook: Average spectra over a set number of bands\n",
    " 10. Apply terrain corrections to remove shadows and order terrain-induces artefacts\n",
    "\n",
    "\n",
    "[asf]:               https://asf.alaska.edu/how-to/data-tools/data-tools/#bulk_download\n",
    "[sentinel-1-snappy]: https://github.com/crisjosil/InSAR_Snappy\n",
    "[atmospheric-corrections]: https://doi.org/10.1016/j.jappgeo.2009.03.010\n",
    "[atmopspheric-data]: https://cds.climate.copernicus.eu/cdsapp#!/dataset/reanalysis-era5-pressure-levels?tab=overview \"Mu√±oz Sabater, J., (2021) was downloaded from the Copernicus Climate Change Service (C3S) Climate Data Store\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Prerequisites\n",
    "The following software are required on your platform:\n",
    " - A [conda](https://www.anaconda.com/products/distribution) (or [mamba](https://github.com/mamba-org/mamba)) installation\n",
    " - The [SNAP and Sentinel toolboxes](https://step.esa.int/main/download/snap-download/) \n",
    "\n",
    "The Python 3.6 environment is defined in the [environment.yml](../environment.yml) file distributed with this package.\n",
    "\n",
    "\n",
    "### Main setup steps:\n",
    " 1. Create a working enviornment\n",
    "  ```\n",
    "  conda create -f environment.yml\n",
    "  ```\n",
    " 2. Install SNAP and follow the instructions to link it with the python environment you created above. \n",
    "    1. Open a SNAP command Line\n",
    "    2. use the `snappy-conf` command with the following arguments\n",
    "    ```\n",
    "        snappy-conf Python Dir\n",
    "    ```\n",
    "    with the following arguments:\n",
    "    - `Python`: Full path to Python executable to be used with SNAP. e.g.        <your_home>\\mambaforge\\envs\\insar\\python.exe\n",
    "    - `Dir`:    Directory where the 'snappy' module should be installed e.g.   <your_home>\\mambaforge\\envs\\insar\\python\\Lib.\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "\n",
    "sys.path.append(\"../\") # go to parent dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Get data\n",
    "\n",
    "### SAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from data import download_2015NepalEarthquake as dl\n",
    "\n",
    "downloader = dl.bulk_downloader()\n",
    "downloader.download_files()\n",
    "\n",
    "for file in glob.glob(\"*.zip\"):\n",
    "    new_file = os.path.join(\"..\", \"data\", file)\n",
    "    shutil.copy(file, new_file)\n",
    "    if os.path.isfile(new_file):\n",
    "        os.remove(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Preprocess data\n",
    "\n",
    "### SAR\n",
    "\n",
    "\n",
    "#### `snappy` pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading...\n",
      "Reading...\n",
      "Apply TOPSAR Split...\n",
      "Apply TOPSAR Split...\n",
      "Applying orbit file ...\n"
     ]
    }
   ],
   "source": [
    "from sar import InSAR_Pipeline as isp\n",
    "import os\n",
    "\n",
    "file_prefix = \"../infiles\"\n",
    "output_prefix = \"../outfiles\"\n",
    "scene = \"kumamoto_2016\"\n",
    "IW =  \"IW1\"\n",
    "\n",
    "firstBurstIndex = 1\n",
    "lastBurstIndex = 9\n",
    "ML_nRgLooks = 6\n",
    "\n",
    "output_dir = scene + \"_\" + IW + \"_\" + \"wsl\"\n",
    "output_path = os.path.join(output_prefix, output_dir)\n",
    "\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "# Nepal 2015 nepal_2015\n",
    "if scene == \"nepal_2015\":\n",
    "    filename_1 = os.path.join(file_prefix,'S1A_IW_SLC__1SSV_20150417T001852_20150417T001922_005516_0070C1_460B.zip')\n",
    "    filename_2 = os.path.join(file_prefix,'S1A_IW_SLC__1SDV_20150429T001907_20150429T001935_005691_0074DC_7332.zip')\n",
    "\n",
    "# Rockridge 2019 rockridge_2019\n",
    "elif scene == \"rockridge_2019\":\n",
    "    filename_1 = os.path.join(file_prefix,'S1B_IW_SLC__1SDV_20190626T020647_20190626T020714_016861_01FB9D_6003.zip')\n",
    "    filename_2 = os.path.join(file_prefix,'S1B_IW_SLC__1SDV_20190708T020648_20190708T020715_017036_0200CC_D043.zip')\n",
    "\n",
    "# Kumamoto Earthquake 2016 kumamoto_2016\n",
    "elif scene == \"kumamoto_2016\":\n",
    "    filename_1 = os.path.join(file_prefix,'S1A_IW_SLC__1SSV_20160408T091355_20160408T091430_010728_01001F_83EB.zip')\n",
    "    filename_2 = os.path.join(file_prefix,'S1A_IW_SLC__1SSV_20160420T091355_20160420T091423_010903_010569_F9CE.zip')\n",
    "\n",
    "else:\n",
    "    raise RuntimeError(\"Specify a valid scene\")\n",
    "\n",
    "\n",
    "# Define input/output files\n",
    "out_filename_i =os.path.join(output_path, 'InSAR_pipeline_I')\n",
    "\n",
    "in_filename_ii =os.path.join(output_path, 'InSAR_pipeline_I.dim')\n",
    "out_filename_ii =os.path.join(output_path, 'InSAR_pipeline_II')\n",
    "\n",
    "in_filename_iii = os.path.join(output_path, 'InSAR_pipeline_II.dim')\n",
    "out_filename_iii =os.path.join(output_path, 'InSAR_pipeline_III')\n",
    "\n",
    "in_filename_iv = os.path.join(output_path, 'InSAR_pipeline_II.dim')\n",
    "out_filename_iv =os.path.join(output_path, 'InSAR_pipeline_IV_snaphu_test')\n",
    "\n",
    "\n",
    "# Call the processing pipeline step by step\n",
    "isp.InSAR_pipeline_I(filename_1, filename_2, IW, firstBurstIndex, lastBurstIndex, out_filename_i)\n",
    "\n",
    "isp.InSAR_pipeline_II(in_filename_ii, ML_nRgLooks, out_filename_ii)\n",
    "\n",
    "isp.InSAR_pipeline_III(in_filename_iii, out_filename_iii)\n",
    "\n",
    "isp.InSAR_pipeline_IV(in_filename_iv, out_filename_iv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Phase unwrapping\n",
    "\n",
    "Phase unwrapping is conducted with `snaphu` outside of the SNAP pipelines. It is ran from the console, using\n",
    "``` bash\n",
    "    $ snaphu n-f snapu.conf Phase_VV_<file>.img <num>\n",
    "```\n",
    "the the full namme of `<file>` and the number `<num>` is found at line 7 of the `snaphu.conf` file created by the last processing step.\n",
    "\n",
    "**NOTE** As of submission time this step must be done manually, but it be easily scriptable in python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.15 ('insar')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "de362d697049f7a6fd0f7c5ca084f4d26671dda19a4bab628313383959fb3ce3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
